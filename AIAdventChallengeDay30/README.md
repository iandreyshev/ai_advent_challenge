# День 30: Персональный AI-агент

Интерактивный AI-агент с персонализацией через YAML-конфиг и системой памяти между сессиями.

## Возможности

- **Профиль пользователя** — агент знает ваше имя, роль, привычки, проекты и предпочтения
- **Персонализированные ответы** — стиль общения подстраивается под профиль
- **Память между сессиями** — агент запоминает важные факты из разговоров
- **Авто-извлечение фактов** — автоматически находит и сохраняет важную информацию
- **Факты от третьего лица** — LLM перефразирует факты ("у меня голубые глаза" → "У Ивана голубые глаза")
- **Стриминг ответов** — токены выводятся в реальном времени

## Требования

- Python 3.8+
- [Ollama](https://ollama.ai/) запущена локально
- PyYAML

## Установка

```bash
pip install pyyaml
ollama pull qwen2.5
```

## Запуск

```bash
# Базовый запуск
python3 agent.py

# С указанием профиля и модели
python3 agent.py --profile my_profile.yaml --model llama3

# Без автоматического запоминания фактов
python3 agent.py --no-auto-memory
```

## Настройка профиля

Отредактируйте `profile.yaml` под себя:

```yaml
name: "Ваше имя"
role: "Ваша роль"

preferences:
  style: "дружелюбный"
  topics:
    - "ваша тема"

habits:
  work_hours: "9:00-18:00"
  tools:
    - "ваш инструмент"

context:
  current_projects:
    - "ваш проект"
  goals:
    - "ваша цель"

agent:
  name: "Имя агента"
  tone: "дружелюбный"
  behavior: "отвечай кратко и по делу"
  greeting: "Привет, {user_name}!"
```

## Команды

| Команда | Описание |
|---------|----------|
| `/profile` | Показать текущий профиль |
| `/remember <факт>` | Запомнить факт |
| `/memory` | Показать сохранённые факты |
| `/forget` | Очистить память |
| `/clear` | Очистить историю чата |
| `/model <имя>` | Сменить модель |
| `/help` | Справка |
| `exit` / `quit` | Выход |

## Структура

```
├── agent.py          — главный скрипт
├── user_profile.py   — загрузка профиля из YAML
├── memory.py         — persistent memory
├── prompts.py        — шаблоны промптов
├── profile.yaml      — конфиг профиля
└── README.md
```
